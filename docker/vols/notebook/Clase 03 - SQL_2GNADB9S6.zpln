{
  "paragraphs": [
    {
      "text": "print(s\"\"\"%html\n\u003ccenter\u003e\n    \u003ch1\u003e\u003ca href\u003d\"http://diplodatos.famaf.unc.edu.ar/\"\u003eDiplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\u003c/a\u003e\u003c/h1\u003e\n    \u003ch2\u003eCurso \u003ca href\u003d\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\"\u003eProgramación Distribuida sobre Grandes Volúmenes de Datos\u003c/a\u003e\u003c/h2\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h3\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"$baseDir/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.310",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ccenter\u003e\n    \u003ch1\u003e\u003ca href\u003d\"http://diplodatos.famaf.unc.edu.ar/\"\u003eDiplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\u003c/a\u003e\u003c/h1\u003e\n    \u003ch2\u003eCurso \u003ca href\u003d\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\"\u003eProgramación Distribuida sobre Grandes Volúmenes de Datos\u003c/a\u003e\u003c/h2\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h3\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424310_1641106768",
      "id": "20161011-125025_834797080",
      "dateCreated": "2021-11-13 21:53:44.310",
      "status": "READY"
    },
    {
      "title": "",
      "text": "%md\n### Antes de comenzar\n#### En máquina virtual\n1. Lanzar terminal\n1. Actualizar repo:\n```sh\ncd diplodatos_bigdata\ngit pull\n```\n1. Lanzar [Zeppelin](http://zeppelin.apache.org/) en docker:\n```sh\n./docker/zeppelin.sh\n```\n1. En navegador abrir [http://localhost:8080](http://localhost:8080)\n1. Seleccionar `Import note`\n1. Elegir json en `diplodatos_bigdata/clases/03_sql/note.zpln`\n2. Seleccionar `Clase 03 - SQL`\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.310",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "title": false,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eAntes de comenzar\u003c/h3\u003e\n\u003ch4\u003eEn máquina virtual\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eLanzar terminal\u003c/li\u003e\n\u003cli\u003eActualizar repo:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class\u003d\"language-sh\"\u003ecd diplodatos_bigdata\ngit pull\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eLanzar \u003ca href\u003d\"http://zeppelin.apache.org/\"\u003eZeppelin\u003c/a\u003e en docker:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class\u003d\"language-sh\"\u003e./docker/zeppelin.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eEn navegador abrir \u003ca href\u003d\"http://localhost:8080\"\u003ehttp://localhost:8080\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eSeleccionar \u003ccode\u003eImport note\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eElegir json en \u003ccode\u003ediplodatos_bigdata/clases/03_sql/note.zpln\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eSeleccionar \u003ccode\u003eClase 03 - SQL\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424310_1043339973",
      "id": "20171024-161854_528178880",
      "dateCreated": "2021-11-13 21:53:44.310",
      "status": "READY"
    },
    {
      "text": "%md\n# Datasets/Dataframes\n\n* Spark permite interactuar con datos estructurados (Bases de Datos tabulares) o semiestructurados (JSON) con su componente **Spark SQL**.\n* Sus interfaces son **SQL** y **Dataframe/Dataset** API .\n    - Programática, parecida a [Python Pandas dataframes](http://pandas.pydata.org/pandas-docs/stable/dsintro.html).\n    - Demasiado parecida. Ver [Koalas](https://github.com/databricks/koalas).\n* La API Dataset es tipada y solo existe para Scala y Java.\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.310",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eDatasets/Dataframes\u003c/h1\u003e\n\u003cul\u003e\n  \u003cli\u003eSpark permite interactuar con datos estructurados (Bases de Datos tabulares) o semiestructurados (JSON) con su componente \u003cstrong\u003eSpark SQL\u003c/strong\u003e.\u003c/li\u003e\n  \u003cli\u003eSus interfaces son \u003cstrong\u003eSQL\u003c/strong\u003e y \u003cstrong\u003eDataframe/Dataset\u003c/strong\u003e API .\n    \u003cul\u003e\n      \u003cli\u003eProgramática, parecida a \u003ca href\u003d\"http://pandas.pydata.org/pandas-docs/stable/dsintro.html\"\u003ePython Pandas dataframes\u003c/a\u003e.\u003c/li\u003e\n      \u003cli\u003eDemasiado parecida. Ver \u003ca href\u003d\"https://github.com/databricks/koalas\"\u003eKoalas\u003c/a\u003e.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eLa API Dataset es tipada y solo existe para Scala y Java.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424310_777478089",
      "id": "20161011-125142_1705237118",
      "dateCreated": "2021-11-13 21:53:44.310",
      "status": "READY"
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/unified_stack.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases/03_sql/unified_stack.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_1115671952",
      "id": "20161011-132101_236091967",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "title": "API 2.x.x unificada",
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/dataset_dataframe_unificado.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/dataset_dataframe_unificado.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_1958593044",
      "id": "20161011-134614_1124280099",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "text": "%md\n### SparkSession\n\n* Para acceder al cluster desde la API se utiliza `SparkSession`.\n* El `SparkContext` deriva de él.\n\n```python\nfrom pyspark.sql import SparkSession\n\nspark \u003d SparkSession \\\n    .builder \\\n    .appName(\"Python Spark ejemplo\") \\\n    .config(\"spark.some.config.option\", \"algun-valor\") \\\n    .getOrCreate()\n    \nsc \u003d spark.sparkContext\n\n```\n\n* En Zeppelin ya están predefinidos: \n  - `SparkSession` objeto `spark` \n  - `SparkContext` objeto `sc`\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eSparkSession\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003ePara acceder al cluster desde la API se utiliza \u003ccode\u003eSparkSession\u003c/code\u003e.\u003c/li\u003e\n  \u003cli\u003eEl \u003ccode\u003eSparkContext\u003c/code\u003e deriva de él.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class\u003d\"python\"\u003efrom pyspark.sql import SparkSession\n\nspark \u003d SparkSession \\\n    .builder \\\n    .appName(\u0026quot;Python Spark ejemplo\u0026quot;) \\\n    .config(\u0026quot;spark.some.config.option\u0026quot;, \u0026quot;algun-valor\u0026quot;) \\\n    .getOrCreate()\n    \nsc \u003d spark.sparkContext\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n  \u003cli\u003eEn Zeppelin ya están predefinidos:\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003eSparkSession\u003c/code\u003e objeto \u003ccode\u003espark\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003eSparkContext\u003c/code\u003e objeto \u003ccode\u003esc\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_1620736359",
      "id": "20161011-174856_51715674",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "text": "%md\n### Lectura de datos\n\n#### Estructurados y semiestructurados\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eLectura de datos\u003c/h3\u003e\n\u003ch4\u003eEstructurados y semiestructurados\u003c/h4\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_252439992",
      "id": "20171020-102828_1480663464",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "text": "%md\n\n#### Formatos:\n\n* json\n* csv\n* parquet\n* orc\n* libsvm\n* text\n* ...\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eFormatos:\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003ejson\u003c/li\u003e\n  \u003cli\u003ecsv\u003c/li\u003e\n  \u003cli\u003eparquet\u003c/li\u003e\n  \u003cli\u003eorc\u003c/li\u003e\n  \u003cli\u003elibsvm\u003c/li\u003e\n  \u003cli\u003etext\u003c/li\u003e\n  \u003cli\u003e\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_802101128",
      "id": "20171019-163121_1592075078",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "text": "%md\n#### Fuentes de datos:\n\n* Archivos en fs local o distribuid (ej hdfs)\n* jdbc (posgress, oracle, mysql,...)\n* Apache Hive (se usa execution backend Spark en ves de MR)\n* Amazon Redshift, S3\n* Azure Storage Services\n* Cassandra\n* MongoDB\n* Neo4j\n* ...",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eFuentes de datos:\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003eArchivos en fs local o distribuid (ej hdfs)\u003c/li\u003e\n  \u003cli\u003ejdbc (posgress, oracle, mysql,\u0026hellip;)\u003c/li\u003e\n  \u003cli\u003eApache Hive (se usa execution backend Spark en ves de MR)\u003c/li\u003e\n  \u003cli\u003eAmazon Redshift, S3\u003c/li\u003e\n  \u003cli\u003eAzure Storage Services\u003c/li\u003e\n  \u003cli\u003eCassandra\u003c/li\u003e\n  \u003cli\u003eMongoDB\u003c/li\u003e\n  \u003cli\u003eNeo4j\u003c/li\u003e\n  \u003cli\u003e\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_2063082915",
      "id": "20171020-102923_1888981134",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "text": "%md\n### Ejemplo\n\n#### Tabla de perfiles [last.fm](last.fm)\n\nFormato:\n\n    id \\t gender (\u0027m\u0027|\u0027f\u0027|empty) \\t age (int|empty) \\t country (str|empty) \\t registered (date|empty)\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEjemplo\u003c/h3\u003e\n\u003ch4\u003eTabla de perfiles \u003ca href\u003d\"last.fm\"\u003elast.fm\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eFormato:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eid \\t gender (\u0026#39;m\u0026#39;|\u0026#39;f\u0026#39;|empty) \\t age (int|empty) \\t country (str|empty) \\t registered (date|empty)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_1681265385",
      "id": "20171020-170028_1956391103",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "text": "%sh\nhead ../../diplodatos_bigdata/ds/userid-profile.tsv\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 14.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_1686435309",
      "id": "20181011-192611_2092112872",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "title": "Lectura",
      "text": "%pyspark\n\nprofiles \u003d spark.read.load(\"../../diplodatos_bigdata/ds/userid-profile.tsv\",\n                    format\u003d\"csv\", delimiter\u003d\"\\t\", header\u003dTrue, inferSchema\u003dTrue)\n                    \n# Ver en schema siguiente si inferSchema\u003dFalse\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_1902693908",
      "id": "20171019-160931_1102056402",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "title": "Esquema",
      "text": "%pyspark\n\nprofiles.printSchema()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.311",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424311_1221849000",
      "id": "20171020-165528_926197483",
      "dateCreated": "2021-11-13 21:53:44.311",
      "status": "READY"
    },
    {
      "title": "Ver el contenido",
      "text": "%pyspark\n\nprofiles.show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.312",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424312_2009057816",
      "id": "20191126-024041_1950604952",
      "dateCreated": "2021-11-13 21:53:44.312",
      "status": "READY"
    },
    {
      "title": "Tambien se puede ver con Zeppelin",
      "text": "%pyspark\n\nz.show(profiles.limit(20)) # limit(n) devuelve solo las primeras n filas \n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.312",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "id": "string",
                      "gender": "string",
                      "age": "string",
                      "country": "string",
                      "registered": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424312_957631527",
      "id": "20191126-023810_382641811",
      "dateCreated": "2021-11-13 21:53:44.312",
      "status": "READY"
    },
    {
      "title": "Query SQL plano",
      "text": "%pyspark\n\nprofiles.createOrReplaceTempView(\"users\")\n\n#Cantidad de usuarios por país\nnUsr4Ctry \u003d spark.sql(\"SELECT country, count(*) AS cantidad FROM users GROUP BY country ORDER BY cantidad DESC\")\n\nnUsr4Ctry.show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.313",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424312_1053598537",
      "id": "20171020-195004_405222821",
      "dateCreated": "2021-11-13 21:53:44.312",
      "status": "READY"
    },
    {
      "title": "Query SQL programático",
      "text": "%pyspark\n\nfrom pyspark.sql.functions import count\n\nnUsr4Ctry2 \u003d profiles \\\n                .groupBy(\"country\").agg(count(\"*\").alias(\"cantidad\")) \\\n                .orderBy(\"cantidad\", ascending\u003dFalse)\n# Cada operación SQL es un método\n\nnUsr4Ctry2.show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.313",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424313_1595851976",
      "id": "20171020-181216_461915575",
      "dateCreated": "2021-11-13 21:53:44.313",
      "status": "READY"
    },
    {
      "title": "Ejercicio",
      "text": "%md\nComplete los siguientes programas que calculan en un Dataframe la cantidad de usuarios por pais desagregando por sexo y ordenando por la cantidad de mayor a menor, usando **SQL plano y programático**.\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.313",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eComplete los siguientes programas que calculan en un Dataframe la cantidad de usuarios por pais desagregando por sexo y ordenando por la cantidad de mayor a menor, usando \u003cstrong\u003eSQL plano y programático\u003c/strong\u003e.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424313_1337691069",
      "id": "20171023-114452_748688701",
      "dateCreated": "2021-11-13 21:53:44.313",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# Con SQL plano\n\nnUsr4CtryGen \u003d spark.sql(\"SELECT country, gender, count(*) AS cantidad FROM users GROUP BY ... ORDER BY ...\")\n\nnUsr4CtryGen.show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424313_879876168",
      "id": "20191126-025015_908338399",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# Con SQL porgramático\n\nnUsr4CtryGen2 \u003d profiles \\\n                .groupBy(\"country\", ...).agg(count(\"*\").alias(\"cantidad\")) \\\n                .orderBy(\"cantidad\", ...)\n\nnUsr4CtryGen2.show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "title": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1359388348",
      "id": "20191126-030740_538459228",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "title": "Lectura desde JDBC",
      "text": "%md\n```python\ndf \u003d spark.read \\\n    .format(\"jdbc\") \\\n    .option(\"url\", \"jdbc:postgresql://localhost/test\") \\\n    .option(\"dbtable\", \"projects\") \\\n    .option(\"user\", \"username\") \\\n    .option(\"password\", \"password\") \\\n    .load()\n```\nMás información en:\n\n* [Spark SQL](http://spark.apache.org/docs/latest/sql-programming-guide.html#jdbc-to-other-databases).\n* [Ejemplo](https://supergloo.com/spark-sql/spark-sql-mysql-python-example-jdbc/).\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cpre\u003e\u003ccode class\u003d\"python\"\u003edf \u003d spark.read \\\n    .format(\u0026quot;jdbc\u0026quot;) \\\n    .option(\u0026quot;url\u0026quot;, \u0026quot;jdbc:postgresql://localhost/test\u0026quot;) \\\n    .option(\u0026quot;dbtable\u0026quot;, \u0026quot;projects\u0026quot;) \\\n    .option(\u0026quot;user\u0026quot;, \u0026quot;username\u0026quot;) \\\n    .option(\u0026quot;password\u0026quot;, \u0026quot;password\u0026quot;) \\\n    .load()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMás información en:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/sql-programming-guide.html#jdbc-to-other-databases\"\u003eSpark SQL\u003c/a\u003e.\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://supergloo.com/spark-sql/spark-sql-mysql-python-example-jdbc/\"\u003eEjemplo\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_795419272",
      "id": "20171023-092655_178501000",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "title": "Lectura desde HIVE",
      "text": "%md\n\n```scala\nwarehouse_location \u003d abspath(\u0027spark-warehouse\u0027)\n\nspark \u003d SparkSession \\\n    .builder \\\n    .appName(\"Ejemplo Spark Hive\") \\\n    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\nsqlDF \u003d spark.sql(\"SELECT key, value FROM src WHERE key \u003c 10 ORDER BY key\")\n```\nMás información en:\n\n* [Spark SQL](https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables).\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003ewarehouse_location \u003d abspath(\u0026#39;spark-warehouse\u0026#39;)\n\nspark \u003d SparkSession \\\n    .builder \\\n    .appName(\u0026quot;Ejemplo Spark Hive\u0026quot;) \\\n    .config(\u0026quot;spark.sql.warehouse.dir\u0026quot;, warehouse_location) \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\nsqlDF \u003d spark.sql(\u0026quot;SELECT key, value FROM src WHERE key \u0026lt; 10 ORDER BY key\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMás información en:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables\"\u003eSpark SQL\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1673532216",
      "id": "20171023-093701_2112740736",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "text": "%md\n### Escritura de tablas",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEscritura de tablas\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_551821205",
      "id": "20171023-115539_2069683705",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "title": "SQL",
      "text": "%pyspark\n\nspark.sql(\"drop table if exists mytable\") # borro la tabla si existe\n\nspark.sql(\"create table mytable as select * from users\") # users ya fue creado\n# Simula Hive Data Warehouse local\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1824916650",
      "id": "20171023-115517_1163412651",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "title": "Dataframe",
      "text": "%pyspark\n\nprofiles.write.mode(\"overwrite\").save(\"./profiles.parquet\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1967644361",
      "id": "20171023-115718_1445962443",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "text": "%sh\nls -ld ./spark-warehouse\nls -l ./spark-warehouse\n\nls -ld ./*.parquet",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 14.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1057193948",
      "id": "20171023-165238_672281439",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "text": "%pyspark\nspark.sql(\"SHOW Tables\").show()",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "database": "string",
                      "tableName": "string",
                      "isTemporary": "string"
                    },
                    "updated": true
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1012479013",
      "id": "paragraph_1634321466906_1716543956",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "title": "Ejercicio",
      "text": "%md\nComplete el siguiente programa par calcular la edad promedio por género y guarde el resultado como tabla SQL y como archivo parquet.\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eComplete el siguiente programa par calcular la edad promedio por género y guarde el resultado como tabla SQL y como archivo parquet.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_519510494",
      "id": "20171023-164954_326955331",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "title": "",
      "text": "%pyspark\n\n# Como tabla SQL\n\nspark.sql(\"drop table if exists gen_prom\") # borro la tabla si existe\n\nspark.sql(\"create table gen_prom as SELECT gender, avg(...) AS age_avg FROM users GROUP BY ...\")\n\n#Cargo tabla y muestro su contenido\n\nspark.sql(\"select * from gen_prom\").show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "title": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_48096325",
      "id": "20201023-123443_40437356",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# Como parquet\n\nfrom pyspark.sql.functions import ...\n\ngenProm \u003d profiles \\\n            .groupBy(...).agg(avg(...).alias(\"age_avg\"))\n\ngenProm.write.mode(\"overwrite\").save(\"./gen_prom.parquet\")\n\n# Cargo parquet y muestro su contenido\nspark.read.load(\"./gen_prom.parquet\").show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.314",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1435487274",
      "id": "20191128-172216_319223823",
      "dateCreated": "2021-11-13 21:53:44.314",
      "status": "READY"
    },
    {
      "text": "%md\n### Otro ejemplo de query programático SQL programático",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eOtro ejemplo de query programático SQL programático\u003c/h3\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424314_1873910913",
      "id": "paragraph_1634183154525_2053567181",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "text": "%sh\n\ncat ../../diplodatos_bigdata/ds/people.json",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 14.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_416156388",
      "id": "paragraph_1634315423702_324581589",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "title": "Ejemplo",
      "text": "%pyspark\n\ndf \u003d spark.read.json(\"../../diplodatos_bigdata/ds/people.json\")\n\n# Displays the content of the DataFrame to stdout\ndf.show()\n\n# Selecciona todo incrementando la edad\ndf.selectExpr(\"name\", \"age + 1\").show()\n\n# O tambien\ndf.select(\"name\", df.age + 1).show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "title": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_1790523274",
      "id": "20161011-151030_1991021842",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# Selecciona personas con mas de 21 años\ndf.filter(\"age \u003e 21\").show()\n\n# Cuenta personas por edad\ndf.groupBy(\"age\").count().show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "fontSize": 14.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_1046693160",
      "id": "20171024-102324_940444908",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "title": "Mas Información en",
      "text": "%md\n\n* [API Python SQL](http://spark.apache.org/docs/2.2.1/api/python/pyspark.sql.html)\n* [Function Reference](http://spark.apache.org/docs/2.2.1/api/python/pyspark.sql.html#module-pyspark.sql.functions)\n* [Doc Spark SQL](http://spark.apache.org/docs/2.2.1/sql-programming-guide.html)\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/2.2.1/api/python/pyspark.sql.html\"\u003eAPI Python SQL\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/2.2.1/api/python/pyspark.sql.html#module-pyspark.sql.functions\"\u003eFunction Reference\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/2.2.1/sql-programming-guide.html\"\u003eDoc Spark SQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_1195089797",
      "id": "20161012-103356_1938807399",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "text": "%md\n### Eficiencia\n\nLos **RDD** tienen el overhead de la *serialización*:\n\n* cuando los objetos se transfieren (por red) y guardan (disco)\n* overhead de garbage collector\n\nLos **Datasets** solucionan estos problemas:\n\n* Serializa a binario usando **encoders**\n    - parte del proyecto Tungsten\n    - permite operaciones sin deserializar\n    - corre *off-heap* (sin garbage collection)\n    - código para serialización generado en forma dinámica\n* Con la información de la estructura (*schema*) Spark hace optimizaciones.\n    - Usa *Catalyst optimizer*.\n    - Transfiere solo columnas usadas, no objetos enteros (relational query plan).\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEficiencia\u003c/h3\u003e\n\u003cp\u003eLos \u003cstrong\u003eRDD\u003c/strong\u003e tienen el overhead de la \u003cem\u003eserialización\u003c/em\u003e:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003ecuando los objetos se transfieren (por red) y guardan (disco)\u003c/li\u003e\n  \u003cli\u003eoverhead de garbage collector\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLos \u003cstrong\u003eDatasets\u003c/strong\u003e solucionan estos problemas:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eSerializa a binario usando \u003cstrong\u003eencoders\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003eparte del proyecto Tungsten\u003c/li\u003e\n      \u003cli\u003epermite operaciones sin deserializar\u003c/li\u003e\n      \u003cli\u003ecorre \u003cem\u003eoff-heap\u003c/em\u003e (sin garbage collection)\u003c/li\u003e\n      \u003cli\u003ecódigo para serialización generado en forma dinámica\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eCon la información de la estructura (*schema*) Spark hace optimizaciones.\n    \u003cul\u003e\n      \u003cli\u003eUsa \u003cem\u003eCatalyst optimizer\u003c/em\u003e.\u003c/li\u003e\n      \u003cli\u003eTransfiere solo columnas usadas, no objetos enteros (relational query plan).\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_1611356519",
      "id": "20161011-174737_215333010",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "title": "WordCount con RDD",
      "text": "%pyspark\n\nlinesRDD \u003d sc.textFile(\"README.md\")\n\nwordsRDD \u003d linesRDD \\\n            .flatMap(lambda l: l.split(\" \")) \\\n            .filter(lambda w:  w)\n#MapReduce:\nwordCountRDD \u003d wordsRDD.map(lambda w: (w,1)) \\\n                .reduceByKey(lambda nx,ny:  nx+ny)\n\nresultRDD \u003d wordCountRDD \\\n                .sortBy((lambda p: p[1]), ascending \u003d False)\n                # ordena por cantidad\n\nprint(\"Resultado:\")\n\nfor w, c in resultRDD.collect()[:5]: #  traigo resultados\n    print(w, c)\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_86688673",
      "id": "20201023-123509_121589787",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "title": "WordCount con DataFrames",
      "text": "%pyspark\n\nfrom pyspark.sql.functions import split, explode\n\nlinesDF \u003d spark.read.text(\"README.md\").toDF(\"lineas\")\n\nwordsDF \u003d linesDF \\\n            .select(explode(split(\"lineas\", \u0027 \u0027)).alias(\"words\")) \\\n            .filter(\"words !\u003d \u0027\u0027\")\n\nwordCountDF \u003d wordsDF \\\n                .groupBy(\"words\").count()\n\nresultDF \u003d wordCountDF \\\n                .orderBy(\"count\", ascending\u003dFalse)\n#                // ordena por cantidad\n\nprint(\"Resultado:\")\n\nresultDF.show(n\u003d5, truncate\u003dFalse)\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_400319758",
      "id": "20201023-123527_1290957379",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/Distributed-Wordcount-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/Distributed-Wordcount-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_1533864636",
      "id": "20161011-201107_202795512",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/Memory-Usage-when-Caching-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/Memory-Usage-when-Caching-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_138246456",
      "id": "20161011-201419_1048673058",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "text": "%md\n#### Tungsten en acción",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eTungsten en acción\u003c/h4\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_195596869",
      "id": "paragraph_1634182605221_1380886083",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "title": "Tungsten en acción",
      "text": "%pyspark\n\nints \u003d range(pow(10, 6))\nprint(ints[:10])\nintsRDD \u003d sc.parallelize(ints).setName(\"intsRDD\").cache()\n\n# Fuerzo evaluacion\nprint(intsRDD.count())\n\n# Ver sparkui storage.\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.315",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "fontSize": 14.0,
        "title": false,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424315_434457617",
      "id": "20161017-104100_1861019655",
      "dateCreated": "2021-11-13 21:53:44.315",
      "status": "READY"
    },
    {
      "title": "Tungsten en acción",
      "text": "%pyspark\n\nints \u003d range(pow(10, 6))\n\nfrom pyspark.sql.types import IntegerType\n\nintsDF \u003d spark.createDataFrame(ints, IntegerType()).cache()\nintsDF.cache()\n\nprint(intsDF.count())\n\n# Ver sparkui ahora.",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "fontSize": 14.0,
        "title": false,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_2082823240",
      "id": "paragraph_1634182688863_1554058947",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\nuiHost \u003d sc.getConf().get(\"spark.driver.host\")#.getOrElse(\"localhost\")\nuiPort \u003d sc.uiWebUrl.split(\":\")[-1]\n\ntextNabuco \u003d \"\"\"%html\n%html\nVer resultado en Spark UI Storage\n\u003ca href\u003d\"http://localhost:4040\"\u003ehttp://localhost(host):4040(port)\u003c/a\u003e\u003cbr\u003e\n\"\"\"\n\ntextLocal \u003d \"\"\"%html\nVer resultado en Spark UI Storage\n\u003ca href\u003d\"http://{}:{}\"\u003ehttp://{}(host):{}(port)\u003c/a\u003e\n\"\"\".format(uiHost,uiPort,uiHost,uiPort)\n\nif uiHost \u003d\u003d \"200.16.29.165\":\n    print(textNabuco)\nelse:\n    print(textLocal)\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "Ver resultado en Spark UI Storage\n\u003ca href\u003d\"http://localhost:4040\"\u003ehttp://localhost(host):4040(port)\u003c/a\u003e\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_791214945",
      "id": "20161017-104452_771251326",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "text": "%md\n## Ventajas/desventajas de las diferentes APIs",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eVentajas/desventajas de las diferentes APIs\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_2121167770",
      "id": "20161017-123303_1620980443",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "title": "APIs tipadas y no tipadas",
      "text": "print(s\"\"\"\n%table\nLenguaje\\t Abstracción Principal\nScala \\t Dataset[T] y Dataframe (Datset[Row])\nJava  \\t Dataset[T]\nPython \\t Dataframe\nR \\t Dataframe\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "editorSetting": {},
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "Lenguaje",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": " Abstracción Principal",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "scatter": {
                "xAxis": {
                  "name": "Lenguaje",
                  "index": 0.0,
                  "aggr": "sum"
                },
                "yAxis": {
                  "name": " Abstracción Principal",
                  "index": 1.0,
                  "aggr": "sum"
                }
              },
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "Lenguaje": "string",
                      " Abstracción Principal": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Lenguaje\t Abstracción Principal\nScala \t Dataset[T] y Dataframe (Datset[Row])\nJava  \t Dataset[T]\nPython \t Dataframe\nR \t Dataframe\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_60381282",
      "id": "20161017-123522_72698600",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "title": "Detección de errores",
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/type-safety-spectrum.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/type-safety-spectrum.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_1230308606",
      "id": "20161017-124430_789707578",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "title": "Cuando usar Datasets Dataframes o RDD",
      "text": "%md\n* Si se necesita expresiones de alto nivel, filters, maps, aggregations, promedios, sumatorias, queries SQL, acceso por columna y funciones lambda sobre datos semiestructurados\n    - para desarrollar aplicaciones finales (Data Ingeeniering) usar **Datasets**.\n    - para análisis interactivo (Data Scientist) usar **Dataframes**. \n* Si se necesita mayor seguridad de tipos chequeandolos a tiempo de compilación, objetos JVM, beneficios de optimización Catalyst y código eficiente con Tungsten usar **Datasets**.\n* Si se quiere una API unificada a traves de la la librerías Spark usar **DataFrames** o **Datasets**.\n* Si se quiere trabajar en R no queda otra que usar **DataFrames**.\n* Si se quiere trabajar en Python no queda otra que usar **DataFrames** y recurrir a **RDDs** si se necesita mayor control.\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 12.0,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n\u003cli\u003eSi se necesita expresiones de alto nivel, filters, maps, aggregations, promedios, sumatorias, queries SQL, acceso por columna y funciones lambda sobre datos semiestructurados\n\u003cul\u003e\n\u003cli\u003epara desarrollar aplicaciones finales (Data Ingeeniering) usar \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003epara análisis interactivo (Data Scientist) usar \u003cstrong\u003eDataframes\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSi se necesita mayor seguridad de tipos chequeandolos a tiempo de compilación, objetos JVM, beneficios de optimización Catalyst y código eficiente con Tungsten usar \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere una API unificada a traves de la la librerías Spark usar \u003cstrong\u003eDataFrames\u003c/strong\u003e o \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere trabajar en R no queda otra que usar \u003cstrong\u003eDataFrames\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere trabajar en Python no queda otra que usar \u003cstrong\u003eDataFrames\u003c/strong\u003e y recurrir a \u003cstrong\u003eRDDs\u003c/strong\u003e si se necesita mayor control.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_896281332",
      "id": "20161017-124933_322133526",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "title": "Ejercicio",
      "text": "%md\nCon el dataset `profiles` complete el siguiente código para calcular la cantidad de registraciones por día de la semana.\n\n#### Ayuda:\n\n* En [SQL API Function Reference](http://spark.apache.org/docs/2.2.1/api/python/pyspark.sql.html#module-pyspark.sql.functions) en la sección \"Date time functions\" hay métodos para manipular fechas.\n* [Date and Time Patterns](https://docs.oracle.com/javase/10/docs/api/java/text/SimpleDateFormat.html).\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 14.0,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCon el dataset \u003ccode\u003eprofiles\u003c/code\u003e complete el siguiente código para calcular la cantidad de registraciones por día de la semana.\u003c/p\u003e\n\u003ch4\u003eAyuda:\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eEn \u003ca href\u003d\"http://spark.apache.org/docs/2.2.1/api/python/pyspark.sql.html#module-pyspark.sql.functions\"\u003eSQL API Function Reference\u003c/a\u003e en la sección \u0026ldquo;Date time functions\u0026rdquo; hay métodos para manipular fechas.\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"https://docs.oracle.com/javase/10/docs/api/java/text/SimpleDateFormat.html\"\u003eDate and Time Patterns\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_206945759",
      "id": "20171023-182043_62941752",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\nfrom pyspark.sql.functions import unix_timestamp, from_unixtime\n\nprofiles \u003d spark.read.load(\"../../diplodatos_bigdata/ds/userid-profile.tsv\",\n                    format\u003d\"csv\", delimiter\u003d\"\\t\", header\u003dTrue, inferSchema\u003dTrue)\n\nregByDayOfWeek \u003d profiles.select(\"registered\", unix_timestamp(\"registered\", ...).alias(\"reg_sec\")) \\\n                    .select(\"*\", from_unixtime(...,\"E\").alias(\"day_week\"))\n\n\nz.show(regByDayOfWeek.groupBy(\"day_week\").count())\n",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 14.0,
        "editorHide": false,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "day_week": "string",
                      "count": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                },
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "day_week",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_1396137392",
      "id": "20191128-193328_151154793",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    },
    {
      "title": "Fin",
      "text": "//val baseDir\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases\"\nval baseDir\u003d\"https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases\"\n\nz.put(\"baseDir\", baseDir)\nprint(\"\"\"%html\n\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "2021-11-13 21:53:44.316",
      "progress": 0,
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "fontSize": 9.0,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\nbaseDir: String \u003d https://bitbucket.org/bigdata_famaf/diplodatos_bigdata/raw/HEAD/clases\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1636840424316_1046657518",
      "id": "20161011-125733_1279366716",
      "dateCreated": "2021-11-13 21:53:44.316",
      "status": "READY"
    }
  ],
  "name": "Clase 03 - SQL",
  "id": "2GNADB9S6",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}